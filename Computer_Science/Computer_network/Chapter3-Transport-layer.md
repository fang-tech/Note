# 传输层

## 3.1 概述

- 提供的服务是什么 -> 进程到进程之间逻辑上的message的通信
- 传输协议运行在端系统上
  - 发送方 : 将报文会分解为若干报文段, 分段传输给网络层
  - 接收方 : 将报文段重组为报文, 再提供给应用层
- 传输层怎么将网络层提供的不可靠服务加强, 最后能完成可靠的信息传输
- 复用和解复用
- 传输层协议的对比 : UDP, TCP
  - 两个协议都提供了多路复用和解复用的服务
  - TCP
    - 拥塞控制
    - 流量控制
    - 建立连接
  - UDP
    - 没有额外的服务
  - 都不提供的服务为
    - 延迟保证
    - 带宽保证

## 3.2 多路复用和解复用

- 复用的信息是IP, 网络物理链路, 网络带宽等资源, 实现方式简单来说就是通过port来区分
- 复用的实现 -> socket封装信息与解封装

- TCP实现复用的流程
  - 复用
    - 建立的socket维护了一个六元组, (socket值, 标识连接的四元组(源IP, 源port, 对方IP, 对方port), PID)
    - 通过socket API发送message给目标主机的对应进程
    - socket API通过维护的六元组表, 查询到当前message应该如何封装, 以传递给下一层
  - 解复用
    - 传输到的目标服务器后
    - 目标服务器通过传递过来的信息中的四元组, 查询本地的socket映射表, 从而将对应的信息传递给该socket对应的PID
  - 这里复用了这个主机的IP, 以及其中的网络物理链路, 使得信息的传递能从端到端, 更细分为进程到进程
  - 解复用就是一个拆包对应port号再对应进程号的方式
- UDP实现复用
  - 复用
    - 和TCP一致, 就是socket标识连接的是二元组(目的IP, 目的端口)
  - 解复用
    - 和TCP一致
- 两者之间的对比
  - TCP协议中, 不同的四元组在服务器端查到的socket对应的PID是不同的, 故能精准地区分出来不同来源的报文, 并且会区别他们, 对应到不同的进程
  - 但是UDP协议中, 只会维护目的IP与port, 无法得知源服务器的IP与port, 无法区分来源, 可能会出现冲突

## 3.3 无连接传输 UDP

- 可能会有丢失和乱序
- 对比IP到IP之间的直接通讯, 提升之处在于能实现进程到进程之间的通讯
- 用户数据报协议 : UDP
  - UDP报文段的头部 -> 固定8个字节, 分成两个4字节的部分
    - 源端口号, 目的端口号 (源端口号用于回复)
    - 长度 校验和(用于校验UDP传输的信息在传输的过程中是否出错, 出错了直接丢失)
- 校验和计算关系
  - 检测在被传输报文段中的差错 (如比特反转)
  - 发送方 : 
    - 将报文段的内容视作16比特的整数
    - 校验和 : 报文段的加法和
  - 接收方
    - 重新计算校验和
    - 检查是否相等
      - 不相等 -> 一定出错了
      - 相等 -> 会有残存错误, 但是概率很小

## 3.4 可靠数据传输

###  Rdt2.0

-  致命的错误 -> ACK和NAK的信息本身也会出现发送错误

### Rdt2.1

- 引入了一个序号的机制, 对比原来的过程
  - 在R方给出回复以后, 如果不是ACK, S方都重新发送上次需要的内容, 假设是P0
  - 由于有了信号的标志, R方能检测到出现了重复 -> R方意识到自己给的回复出错 -> 重新回复, 同时把重复的信息丢掉, 防止重复发
  - 没有序号的时候, 如果采取这个策略 (一直发到有ACK为止), 会出现的问题是, R方会有重复的信息, 因为R方是无状态的, 现在相当一个有状态的通信, 维护了已经成功接受到的信息, 但是给出的回复是错误的情况, 实际维护的内容是发过来的分组信息的序号
- Rdt2.1还是2.0都是 "stop and wait协议", 发送后停止, 等待接收方返回确认信息, 这种协议下, 我们为分组标号, 只用0和1即可
  - 具体的序号机制, 序号位是一位, 从发送方的角度出发, 会一直发送同样的序号的信息直到接收到ACK, 接收到以后变换序号位
  - 从接收方的角度 : 如果接收和当前等待的信号位相同的数据包, 则认定为新的消息, 反之为旧的消息

- ACK和NAK作为控制信息, 本身也需要校验和等机制保证可靠

### Rdt2.2

- 引入的新机制是NAK free, 以便后续实现流水线的收发
- 是一种 "言它策略", 不再用NAK标识错误, 而是为ACK标号, 给出错误的ACK标号, 则代表错误
  - 例如, 接收方给的返回本该是的ACK1, 但是给的返回是上一个返回 : ACK0 -> 说明出错了
  - 当前分组的反向确认, 用前一个分组的正向确认代替

### Rdt3.0

- 同时有比特反转和分组丢失的问题

- 解决丢失 : 超时机制, 比如我现在向接收方传递p1, 如果出现了丢失现象 -> 出现死锁
  - 解决方案 :  超时重传 -> 一般时间是一个正常的来回多一点的时间, 无论是数据包丢失还是返回的控制信息丢失, 都采取超时重传, 因为现在重复不是问题
- 超时时间的设置如果不合理 -> 重复收发的问题 -> 效率会降低为原来的50%, 甚至更低, 因为在这次数据包到达并返回控制信息之前, 因为超时时间设置过短, 就重新触发了超时的机制, 会让一个数据包重复收发两次
- 出现的问题 -> 效率问题 -> 在信道比较长的时候, 一个信道能接受非常多的分组, 如果还是 "stop and wait" , 信道的利用率极低

### 流水线协议 : GBN, SR

#### 滑动窗口协议 (slide window)

- sw = 1, rw = 1 -> stop and wait协议

- sw > 1, rw = 1 -> GBN

- sw > 1, rw > 1 -> SR 选择性重发协议

- 发送缓冲区 -> 存放那些已经发送但是没有得到确认的分组, 用于检测重发和超时重发, 可发准备发但是未发的也会存储

- 发送窗口, 发送缓冲区的一个子集, 发送缓冲区的大小是根据物理条件设置的, 而发送窗口是实际的队列, 像是容量和length的区别

  - 每发送一个分组, 前沿向前移动一个单位
  - 每收到一个分组的确认信息, 后沿向前滑动一个单位

- 给出了意外的返回, 比如现在的发送窗口是从0 ~ 3的, 这个时候接受到了分组4的信息, 这个时候做出的动作

  1. 抛弃掉这个乱序分组
  2. 计算出现在的已经给出返回的分组的最高的编号, 比如现在滑动窗口后沿是2, 前沿是3, 那么这个时候, 接受方会给出返回ACK1的确认

- 接收窗口 = 接收缓冲区

  - RW = 1的时候 -> 只能顺序接收 == 只有0号分组可以接收, 只能从0 ~ n以此接收 == GBN
  - RW > 1 => 可以乱序接收
  - RW > 1的时候, 会有一个和发送窗口一样的接收窗口, 里面放了等待的分组, 哪个分组到来就返回ACK几, 不过, 只有序号在最左边的分组接收了, 窗口的后沿才会向前滑动至没有接收到的分组的位置
    - 低序号到来的时候, 接收窗口移动
    - 高序号到来的时候, 缓存但不交付 (不允许失序), 不滑动 
    - 滑动意味着数据的交付, 交付给上一层

- 正常情况下, 两个窗口之间的互动

  - 用户的分组发送 -> 发送窗口的前沿向前滑动 -> 接收窗口向前滑动 -> 返回控制信息 -> 发送窗口的后沿向前滑动 -> 新的分组落入发送窗口 -> 循环往返

- 异常情况下的窗口互动

  - 问题 : 发送方的传递的分组在传输的过程中丢失或出错, 接收方的返回出错
  - 均导致的问题 -> 乱序的发送
  - GBN和SR的运行机制, 都会保证最后到达的分组是正确
  - 但是存在区别, 举例说明 : 成功发送0, 1号分组, 现在我们不断连续发送了2,3,4分组(乱序)
    - GBN : 接收端会返回ACK2, 然后3分组和4分组就会被丢弃掉, 而发送方只维护着一个超时计时器, 分组3和分组4没有接收到, 超时后, 会重发断点后的所有分组, 也就是go back 到2的位置, 重发接下来的分组3和分组4
      - 一旦一个分组发送失败了, 接下来要返回发送失败的分组, 重头再发
    - SR : 发送方只需要单独发送超时的分组, 选择性地的发送, 不需要返回这个操作, 只需要将发送失败的分组重新发送, 每个分组单独的维护着一个定时器
    - GBN : Go back N ; SR : Selective Repeat
    - 定时器开始和关闭计时的时机 -> 发送的时候开始, 成功接收的时候关闭

- GBN和SR的优缺对比

  |      |                       GBN                       |                        SR                         |
  | :--: | :---------------------------------------------: | :-----------------------------------------------: |
  | 优点 | 简单, 所需资源少 (接收方只需要维护一个缓存单元) |                  出错时, 代价小                   |
  | 缺点 |           一旦出错, 回退N步的代价很大           | 复杂, 所需要的资源多 (接收方需要创建多个缓存单元) |

  - 使用的范围
    - 出错率低 : 比较适合GBN, 出错非常罕见, 没有必要用SR
    - 链路容量大(延迟大, 带宽大) : 比较适合SR而不时GBN, 出错的代价太大了

- 发送窗口的最大值, 序号空间为$2^n$
  - SR : $2^{n-1}$
  - GBN : $2^n -1$
  - 用于区分新的数据包和旧的数据包, 这里我们需要引入接收方 "期待" 的数据序号的问题
  - 举例说明, 现在的序号空间是4, 发送了0, 1, 2, 3向接收方
    - GBN : 假设现在的发送空间的大小是4
      - 全部接收成功的时候, 返回ACK3, 这个时候接收方控制信息回传丢失, 发送方超时重传四个分组
      - 这个时候, 接收方并不知道这四个分组是新一轮的分组, 还是上一轮重传的分组
    - GBN : 假设现在的发送空间是3
      - 全部接收成功以后, 返回ACK2
      - 接下来有两种情况
        - 发送方成功接收到了ACK2, 那么发送窗口滑动到[3, 0, 1]并发送, 也就是接收方获取到的分组是[3, 0, 1]
        - 发送方没有接收到ACK2, 那么Go back, 然后超时重传这三个分组[0, 1, 2], 这个时候接收方接收到的分组是[0, 1, 2]
        - 两种情况下的接收是不一样的, 接收方以此能够分辨出来接收到的分组是超时重传的还是新的一轮的分组
    - SR : 假设序号是3位的
      - 发送空间为5的时候, 发送方发送了[0,1,2,3,4]
        - 发送方成功接收到返回的ACK0 ~ 4, 这个时候, 发送窗口滑动到了[5,6,7,0,1]
        - 发送方没有接收到其中的ACK0, ACK1, 这个时候, 发送窗口不动[0,1,2,3,4], 超时重传[0,1]
        - 我们可以发现这两种情况下, 我们会有0,1是重复的, 并且由于SR的乱序确认的, 所以它无法判断传回来的0, 1是超时重传的上一轮次的分组还是新的一轮的分组

##  3.5 面向连接协议 : TCP

- 点到点之间的服务
  - 一个进程到一个进程之间的服务
- 需要上层应用自己维护报文之间的界限
  - TCP会根据MSS, 将原本的报文切分为一段一段的字节流, 并不维护原本的报文的界限问题
  - MSS : 最大报文段大小
- 管道化
  - 拥塞控制, 流量控制
- 发送和接收的缓存
  -  因为发送方和接收方的能力是可能是不一样的
- 全双工数据
  - 同一连接中数据是双向流通的
- 面向连接

###  TCP报文段的结构

![TCP](.\img\TCP.png)

- 序号 : 在TCP按照MSS为一份的大小将报文切分为一段一段的字节流以后, 这个就是TCP报文段的载荷部分(body), 而body部分, 也就是承载的内容的第一个字节在原报文中的偏移量, 就是需要
  - 这里我们会规定序号的起始, 并不是总是以0为开始
  - 举例说明 : 现在我们有一个128字节的报文段, MSS=2, 那么原报文就被切分为64段小的字节流, 我们规定起始的序号是X, 那么第0段TCP报文段的序号就是X, 第1段TCP报文段的序号就是X+1\*MSS
- 确认号 : 假设这里的数字是551, 说明接受方收到550及以前的所有字节, 需要ACK位置1, 才是有效的
- 首部长度, 保留未用

### 往返延迟(RTT)和超时定时

- 超时定时的时间是动态变化的, 根据短时间的情况, 计算出来合适的超时定时
- SampleRTT : 发送方维护一个定时器, 在发送一个报文的时候开始计时, 接收到返回的时候停止计时, TCP是流水线协议, 但是同时只会有一个分组的在被定时器计时, 其他的分组的用时情况不会被关注

-   暴力平均所有的SampleRTT获得到的RTT无法很好的反应当前的网络状况, 故我们采用移动平均值
  - EstimatedRTT = (1 - a)\*EstimatedRTT + a*SampleRTT
  - 过去的样本对平均值的贡献为${(1-\alpha)}^n$ => 呈指数下降
  - 推荐的$\alpha$的为0.125
  - 指数加权移动平均
- 设置超时时间除了考虑平均值还需要考虑分散程度(方差),因为我们想尽可能多的包含情况 
  - $DevRTT = (1-\beta)*DevRTT + \beta*\left\vert {SampleRTT - EstimatedRTT} \right\vert$
  - $\beta$推荐为0.25
- 最终的超时时间设置为EstimatedRTT + 4\*DevRTT

### 可靠数据传输

- 累计确认 (GBN) , 并且表示的自己的期待
- 单个重传定时器 (GBN)
- 是否可以接收乱序是未被规定的事件

- 触发重传
  - 超时
  - 快速重传 => 接收到了三个冗余的 确认

#### TCP 简化版

- 忽略流量控制和拥塞控制

- 发送方的流程
  1. 初始化Seq信号的初始值 => NextSegNum , Sendbase
  2. 接收到了上层传输过来的数据, 创建segment(段)和seg, 这里的seg是下一个要传输的字节段的起始位置
  3. 传递segment给下一层IP
  4. NextSegNum = NextSegNum + length(data) => 类似于发送窗口的前沿向前滑动
     - base ~ next : 发送方已发送但未被确认的字节
  5. 如果没有计时器开始计时, 开启计时器
  6. 如果超时, 重传base对应的segment, 不会将所有未被确认的都重传一遍, 然后重新计时
  7. ACK recieved, with ACK field value y
  8. if (BaseSeg < y) => 说明这个时候后沿在现在已经被确认收到的信息之前 => 移动后沿 BaseSeg = y
  9. 如果移动后沿以后, 前后沿没有相遇, 重新启动定时器, 因为说明还有已发送但是未被确认的字节

#### TCP ACK的建议

- 四种情况, 这里需要引入的一个机制是ACK的延迟, 用于减少对发送方的回复, 以减少对发送方的干扰, 这里设定最大等待时间是500ms

  1. 第一种情况

     - 事件 : 所期望序号的报文段按序到来, 所期望序号的之前的报文段都被确认
     - 动作 : 延迟ACK, 接受到一个ACk以后, 等待500ms, 如果这个时间段内第二个TCPseg没有到, 则发送一个ACK

  2. 第二种情况

     - 事件 : 所期望序号的报文段按序到来, 第二个报文段也到来了
     - 动作 : 对第一种情况的正向的情况的补充, 即在500ms内, 第二个报文段成功接收到了, 发送ACK

  3. 第三种情况

     - 事件 : 比期望报文序号更大的报文发送过来了, 即乱序到达, 检测出数据流中的间隔
     - 动作 : 发送断点位置的ACK, 指明现在期望收到这个断点位置的TCP段

  4. 第四种情况

     - 事件 : 能部分填补或完全填补接收数据间隔的报文段到达

     - 动作 : 若这个报文段填补的是gap的低端, 则发送累计后的ACK

### 流量控制

- 方式 -> 传输的数据中包括缓冲区的剩余大小, 额外的传输成本太高了
- piggybacking => 捎带技术, 在传输的信息中带上缓冲区的大小
  - 在发送方的TCP段头部的rwnd字段(就是头部的接收窗口)告诉空闲buff的大小

### 连接管理

#### 三次握手的内容

- 前两次握手 => 同意建立连接, 每一方都知道对方愿意建立连接, 为连接准备资源: 缓冲区
- 第三次握手 => 同意连接参数 : 初始seg的序号

- 两次握手的失败场景一 : 半连接

  - 请求连接的TCPseg发送到服务器以后, 服务器的确认连接超时回复
  - 发起端重新发送对连接的请求, 这样服务器端单向维护连接, 同时应对新的连接请求, 建立一个新的连接, 并为连接准备资源, 这些虚假的半连接消耗了很多资源

- 两次握手失败场景二 : 旧数据被当成新数据接受了

  1. 客户端发起连接请求但超过定时器设置
  2. 客户端放弃了原先的连接, 发送了新的连接请求
  3. 新的连接完成
  4. 传递data1, 发送超时后以后, 重传data1
  5. 正常通信一段时间以后连接关闭

  - 延迟的连接请求和data1到达, 这个时候服务器收到旧的连接请求后会当成新的连接建立
  - 同时旧的data1也会被当成新的"旧"连接的新数据接收

- 三次握手

  - 第一次 : 选择初始的序号, 发送TCP SYN报文 
    - Seq = x, SYNbit = 1(这是头部的一个bit, 置1的时候说明这是连接建立请求报文)
  - 第二次 :  选择初始序号, y发送SYNACK报文, 确认SYN
    - SYNbit = 1, Seq = y, ACKbit = 1; ACKNUM=x+1
  - 第三次 : 确认对方给出的序号, 一般第三次握手和第一次数据传递同时发生
    - ACKbit = 1, ACKnum=y+1

#### 三次握手是怎么解决二次握手带来的两个问题

- 半连接 : 在第二次收到服务器对于延迟的第一次握手请求的回应的握手请求时, 会拒绝第三次握手, 从而拒绝建立连接
  - 详情 : 客户端现在同样面对的延迟问题, 但是第一次发出握手请求的时候, 携带了第一个seq序列号ISN1(initialize sequence number), 这个请求触发了超时重传机制, 重新发起握手请求, 这个时候携带的是ISN2
  - 这个时候服务器在后续的时候回应延迟的握手请求, 返回的ACKnumber是ISN1+1, 而客户端需要的是ISN2+1
- 旧的数据被当成了新数据
  - 在三次握手的情况下, 旧数据到达的时候压根就没有建立连接
- 一种诡异的情况 : 现在仍然是出现了数据data传输过程中延迟送达, 在传输的过程中, 连接关闭了, 紧接着, 又开始了新的一次连接, 并且双方使用的端口号等信息和上次一致, 这里就会有个问题, 新的连接会接收老的连接滞留的数据
  - 这个时候ISN是随机设置的必要性就体现出来了, 这个时候凭借序号空间之间的差异, 就能区分出来老的和新的连接
  - 但是会极小概率出现连序号空间都是相同的情况, 将ISN和时钟的相关, 取时钟的前32bit作为ISN

#### 连接的拆除 

- 对称释放, 并不完美

- 一端向另一端发送关闭连接的请求, 然后接收到对方给的确认, 然后单边关闭连接, 双边对称进行

  - 关闭请求 : FINbit = 1, seq = x

  - 确认返回 : ACKbit = 1; ACKnum = x+1

- 经历了对称的释放后, 主动方最后再开启计时器, 如果经历了2*max  segment lifetime(TCP报文在网络中的最大生存时间) , 再无信息传递, 关闭连接, 以有时间处理最后可能的重传, 并且等待时间会清空可能会干扰到下一段连接的报文

## 3.6 拥塞控制原理

### 拥塞的原因和代价 : 场景1

- 条件

  - 两个发送端和两个接收端

  - 一个路由器具备无限的缓冲空间 -> 不会有分组丢失

  - 输出链路带宽 : R

  - 没有重传

- 假设输入为$\lambda^{in}$k, 它的值到R/2的时候, 连接的吞吐量到达极限, 但是这个时候的流量强度为1, 排队延迟爆增, 进入的速率越接近极限, 排队延迟增长得越快

### 拥塞的原因和代价 : 场景2

- 场景
  - 一个分组路由器, 有限的缓冲 => 有丢失现象
  - 分组丢失的时候, 重传
    - 应用层的输入和输出是对等的
    - 传输层的输入包括了重传 => $\lambda^{''}_{in} > \lambda_{in}$
  - 发送端知道空闲缓冲区的大小
  - 随着越来越多的输入, 重传的分组在所有分组的比例越来越大, 随着拥塞程度的增加, 想要输出同样的数量的分组, 代价越来越大
  - 同时是一个正反馈调节, 随着重传分组的增加, 网路拥塞的速率加速用于, 是非线性增长

### 拥塞的原因和代价 : 场景3

- 网络拥塞以后, 当分组丢失的时候, 任何"关于这个分组的上游传输能力"都被浪费了

### 拥塞控制

- 网络辅助的拥塞控制 : 网络提供一些是否发送拥塞的显式的信息
- 端到端拥塞控制 : 端系统自己判断是否发生拥塞

#### 网络辅助的拥塞控制

- ATM ABR 拥塞控制
- 传递信息用的是固定长度53byte的信元
- 弹性服务
  - 如果没有发生拥塞的时候 => 发送方可以使用带宽
  - 发生的时候 => 降低到最低保障速度
- RM (资源管理) 信元中有对拥塞情况的标志位
  - NIbit : 轻微拥塞 =. 速率不要增加了
  - CIbit : 拥塞了, 降低速率
- ER字段
  - 每经过一个交换机, 根据能提供的速率设置ER的值, 并且ER = min(ER, now)
  - 发送端因此是最低的可支持速率

## 3.7 TCP拥塞控制

- 使用端到端的拥塞控制 =>
  - 减少的路由器的负担
  - 符合网络核心简单的TCP/IP架构

### 如何检查拥塞

- 发送的段超时 <= 由于分组被路由器抛出, 但也有误动作 => 可能是收到了干扰, 然后TCP段发生错误, 然后没通过校验从而被抛出, 但是误动作发送的概率比常规情况小太多了
- 收到了三个冗余的ACK 

### 控制策略

- 速度控制方法 : rate = CongWin / RTT
- CongWin : 用来控制发送方在收到接收方确认之前能发送的最大的字节数
  - 超时或者收到了3个冗余的ACK, CongWin下降,
    - 超时的时候, CongWin降为1MSS, 进入到SS阶段在倍增到CongWin/2 (每个RTT), 从而进入CA阶段
    - 3个重复 => Config = Config/2, CA阶段
  - 否则, CongWin上升
    - SS阶段 : 加倍增加(每个RTT)
    - CA阶段 : 线性增加

### 联合控制

SendWin = min{CongWin, RevWin} : 发送窗口的大小为接收窗口可用空间和拥塞窗口的最小值, 这样能同时兼顾流量控制和拥塞控制

### 控制流程

线性增加, 乘性减

| 事件                                      | 状态          | TCP 发送端行为                                               | 解释                                                         |
| ----------------------------------------- | ------------- | ------------------------------------------------------------ | ------------------------------------------------------------ |
| 没有被确认的分组收到了ACK                 | 慢启动 (SS)   | CongWin \*= 2, 如果这个时候拥塞窗口大于Threshold, 进入CA拥塞避免阶段 | 每一个RTT, CongWin加倍                                       |
| 没有被确认的分组收到了ACK                 | 拥塞避免 (CA) | 每一次报文ACK的时候CongWin += MSS*(MSS/CongWin),             | 每一个RTT, CongWin+1                                         |
| 收到了三个重复的ACK, 说明出现了轻微的拥塞 | SS or CA      | Threshold = CongWin/2, CongWin = Threshold + 3, 状态等于CA   | 快速重传, 实现乘性的减, CongWin没有直接变为1                 |
| 超时                                      | SS or CA      | Threshold = CongWin/2, CongWin = 1, 状态变为SS               | 进入slow start阶段                                           |
| 重复的ACK                                 | SS or CA      | 对被ACK的segment增加重复ACK的技计数                          | 相当于对于是否出现轻微拥塞情况的等待判断, 期间不需要对Threshold或者CongWin进行变化 |

> - 使用CongWin += MSS*(MSS/CongWin), 而不是在一次RTT结束的时候CongWin += MSS, 能保证不会出现在一次RTT结束后, 如果MSS, 数据量激增的情况, 而是平缓的将其分摊到了RTT过程中每一次ACK上
>
> - 在TCP拥塞的语境下, RTT的含义是收发完一次CongWin大小的数据, 所以在一次RTT中, 发送并收到了CongWin/MSS数量的包

### TCP的吞吐量

平均窗口尺寸 => (3/4)W

### TCP的公平性

有多个主机共用带宽, 采用TCP通讯, 长期来看,  带宽的分配是公平的

- 两个竞争的TCP会话
  - 加性增加, 斜率为1, 吞吐量增加
  - 乘性减, 吞吐量比例减少
- 与之相对的, 能从中看出这是一种相对的公平
  - 是从TCP的数量出发的, 如果现在用两台主机竞争一个链路带宽为R的瓶颈, A主机发起了1个TCP会话, B主机发起了9个TCP的会话, 最后分配时, A获取的带宽是1/10R, 而B是9/10R
  - 从斜率出发, 如果另一个TCP会话的延迟更小, 在第一个TCP会话线性增加一次的时候, 另一个TCP会话已经线性增加了两次了, 这个时候, 斜率趋向于2

- 并不是完全的平衡, 只是一种相对的平衡



