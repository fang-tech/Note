# Redis面试题

## 为什么使用Redis

### 为什么选用Redis作为MySQL数据库的缓存?

## Redis过期删除与缓存淘汰策略

### Redis使用的过期删除策略是什么?

Redis中可以为key设置过期时间, Redis中有单独的一张表用于记录每个key的过期时间

对于删除操作, Redis中有 **懒惰删除** 和 **定期删除** 两种策略

- **懒惰删除** : Redis会在下一次使用到这个key的时候, 先去检查这个key是不是再过期时间表中, 如果在并且已经过期了, 就会将这个key删除, 也就是从内存中释放
  - 优点 : 对CPU时间友好, 占用CPU的时间更少
  - 缺点 : 对缓存不友好, 没有被使用到的key会一直占用内存, 即使它已经过期了
- **定期删除** : 为了补足上面懒惰删除中某些没有被使用的过期key会一直占用内存的问题, Redis还有定期删除的设置, Redis会定期抽取一定数量的key, 并检查它们是不是过期了, 过期了就删除. 如果(过期的key / 所有检查的key) > 25%, 就会立马开启下一轮检查, 因为这个时候说明redis中有很多过期的key. 否则则等待下一轮检查. 同时为了避免这个删除循环过度, 导致线程卡死, redis中对于每一轮还有时间限制, 如果超过最大时间(默认25ms), 也会退出等待下一轮检查
  - 优点 : 能清理过期的且使用频率低的key, 对内存友好, 同时最大时间的设置, 也能限制这个操作占用过多的cpu时间
  - 缺点 : 执行的频率和时间难以把握

### Redis持久时, 对过期键会如何处理?

对于RDB(Redis Database)文件

- **RDB文件生成阶段** : 生成的时候会对key进行过期检查, 过期键不会被写入
- **RDB文件加载阶段** : 需要从主节点和从节点分情况讨论
  - **主节点** : 会进行键的过期检查, 如果键过期了, 就不会加载进Redis中
  - **从节点** : 不会检查, 会将RDB文件中的内容全部重新加载进Redis中, 但是主从节点进行数据同步时候, 从服务器中的数据会被清空, 所以从节点中的过期键也不会造成什么影响

对于AOF(Append Only)文件

- **AOF文件生成阶段 :** 如果持久化的时候, 数据库中的某个过期键还没有被删除, 就会保留这个键, 等到过期键被删除的时候, 会显式地追加一条DEL删除指令.
- **AOF文件重写阶段** : 执行AOF重写的时候, 会对Redis中键进行检查, 已经过期的键不会保存到重写后的AOF文件

### 主从模式下, Redis怎么处理过期键

从服务器不会对过期键做任何处理, 而是在主服务器会对键进行过期检查, 发现键是过期以后, 会在AOF文件中追加一条DEL指令, 同步到所有的从库, 从库通过执行这条DEL指令来删除过期键

### 内存淘汰策略有几种

在内存满了以后, 会触发Redis的内存淘汰策略, 可以通过设置redis的maxmemory参数设置
内存淘汰策略可以大致分为 **不进行数据淘汰策略**, **进行数据淘汰策略**两类

- **不进行数据淘汰策略** : 就是简单的在内存满了(超过设置的最大内存)以后, 不淘汰任何数据, 不再提供服务, 直接返回错误
- **进行数据淘汰的策略** : 又可以再分成两类, 全局淘汰和只在设置了过期时间的键中进行淘汰
  - **全局淘汰** : `allkeys_random` : 全局随机淘汰键, `allkeys_lru` : 全局LRU淘汰, `allkeys_lfu` : 淘汰整个键值中最少使用的键
  - **只在设置了过期时间的键中进行淘汰** : `volatile_random` : 随机淘汰设置了过期时间的键, `volatile_lru` : 淘汰最久未被使用的键, `volatile_lfu` : 淘汰使用次数最少的键, `volatile_ttl` : 淘汰过期时间更早的键

### Redis中的LRU与LFU

> LRU : Least Recently Used : **最近最少使用**

LRU最大的问题是需要维护一个所有数据对象大链表, 以及每次在访问数据项的时候都需要移动链表项, 这两个操作的开销都很大
所以在Redis中的LRU是一种 **近似LRU**, 从而减小LRU算法的开销

- 为每个redis数据对象添加一个**时间戳**属性, 用于记录数据的, 记录数据 **最后一次访问时间**
- Redis在执行缓存淘汰策略的时候, 通过 **随机采样的方式淘汰数据**, **每次随机抽取5个数据(可以配置), 然后淘汰掉其中的时间戳最久远的一个数据项**
但是LRU无法解决 **缓存污染** 的问题

> LFU : Least Frequently Used : **最近最不常用**

Redis记录每个数据项的使用次数

> lru : 24bit

在LRU算法中, 这个24bit的数据记录最近一次访问的时间戳
在LFU算法中, 高16位存储最近访问时间, 低8位存储访问次数

在redis中, 同一时间内, 只会使用一种方式解释lru属性, 在运行期间一般不会随意切换淘汰策略

- 如果从LRU -> LFU : 会将redis对象的lru值初始化(一般是5)
- 如果从LFU  -> LRU : 会用新的解释策略解释lru的值

## Redis缓存设计

### 如何避免缓存雪崩, 缓存击穿, 缓存传透

这里是针对使用redis作为数据库的缓存的时候出现的情况, 一个数据请求的请求顺序在有缓存的情况下会是

1. 请求到redis缓存
   1. 命中 -> 直接返回
   2. 没有命中 -> 尝试从数据库中获取数据并更新redis缓存

> 什么是缓存雪崩?

短时间内大量的key或者是热点数据过期, 导致用户的请求直接跨过redis, 直接请求从数据库中获取数据, 大量的请求直接压垮了数据库. 

这里雪崩的时机是发生在从redis中获取缓存失败, 并且在给redis设置缓存之间发生

> 怎么解决缓存雪崩?

- 将缓存的过期时间随机分散 : 在原本失效的时间基础上增加1-10分钟, 这样就不会出现大量数据同一时间失效的情况
- 设置缓存不过期 : 通过后台程序来设置和更新缓存时间, 避免因为缓存失效带来的缓存雪崩

> 什么是缓存击穿?

缓存击穿是缓存雪崩的一个子情况, 指的是针对于单个热点数据, 在缓存失效的时候, 大量的请求打向了数据库.

> 怎么解决缓存击穿?

- 互斥锁 : 在缓存没有命中之后, "从数据库中获取数据并更新缓存"这个操作设置互斥锁, 也就是保证同一时间只有一个请求是会被打向数据库, 其他的都会等待重试, 重新尝试从缓存中获取数据

```java
function getData(key) {
    // 1. 从缓存获取数据
    value = redis.get(key)
    
    // 2. 缓存命中,直接返回
    if (value != null) {
        return value
    }
    
    // 3. 缓存未命中,尝试获取锁
    if (redis.setnx("lock:" + key, "1", expireTime)) {
        try {
            // 4. 从数据库获取数据
            value = db.query(key)
            
            // 5. 将数据写入缓存并设置过期时间
            redis.set(key, value, expireTime)
            
            return value
        } finally {
            // 6. 释放锁
            redis.del("lock:" + key)
        }
    } else {
        // 7. 获取锁失败,等待一段时间后重试
        sleep(50)
        return getData(key) // 递归调用
    }
}
```



- 设置缓存不过期

> 什么是缓存传透?

前两种情况都是数据库中有数据的时候, 还有访问的数据在数据库中不存在的情况, 这个时候, 每个请求都同样会被打向数据库, 这个问题常常是运营方面的配置有问题, 或者有恶意攻击

> 怎么解决缓存传透问题

- 非法请求的限制: 当有大量恶意请求访问不存在的数据的时候, 在API的入口判断请求参数的合理性
- 设置空值或者默认值 : 在线上业务发生缓存传透的现象的时候, 可以针对查询的数据, 在缓存中设置一个空置或者默认值, 后续请求就能识别出来现在发生了缓存传透
- 使用布隆过滤器快速判断数据是否存在, 避免通过查询数据库来判断数据是否存在 : 通过布隆过滤器记录存在的数据, 从而快速判断数据是否存在

### 如何设计一个缓存策略, 可以动态缓存热点数据?

用户访问数据也是具有局部性的, 如果我们能动态缓存热点数据, 能有效地增加缓存命中率, 这是一个典型的热点商品缓存管理

- 通过Redis的Sorted Set创建基于访问时间排序的队列
- 系统定期删除队列最后的200个商品, 然后再从数据库中随机读取中200个商品
- 每次请求到达的时候, 就会先尝试从队列中获取商品ID, 如果命中了, 就根据ID再从另一个缓存数据结构中获取实际的商品信息

```java
// 初始化
function 初始化排序队列():
    如果 Redis中不存在"hot_products_queue":
        product_ids = 从数据库中随机获取1000个商品ID
        对于每个 product_id in product_ids:
            Redis.ZADD("hot_products_queue", 当前时间戳, product_id)
    
    如果 Redis中不存在"products_cache":
        products = 从数据库获取所有在"hot_products_queue"中的商品详情
        对于每个 product in products:
            Redis.HMSET("products_cache:" + product.id, product的所有字段和值)

// 访问商品时更新队列
function 访问商品(product_id):
    // 更新访问时间戳
    Redis.ZADD("hot_products_queue", 当前时间戳, product_id)
    
    // 从缓存获取商品信息
    product_info = Redis.HGETALL("products_cache:" + product_id)
    如果 product_info为空:
        product_info = 从数据库获取product_id的商品信息
        Redis.HMSET("products_cache:" + product_id, product_info的所有字段和值)
    
    返回 product_info

// 定期刷新队列
function 定期刷新队列():
    // 移除排名靠后的200个商品
    old_products = Redis.ZRANGE("hot_products_queue", 0, 199)  // 获取排名最后的200个
    Redis.ZREM("hot_products_queue", old_products)
    
    // 从数据库随机获取200个新商品
    new_products = 从数据库中随机获取200个不在队列中的商品ID
    对于每个 product_id in new_products:
        Redis.ZADD("hot_products_queue", 当前时间戳, product_id)
        
        // 同时确保这些商品的详情也被缓存
        如果 !Redis.EXISTS("products_cache:" + product_id):
            product_info = 从数据库获取product_id的商品信息
            Redis.HMSET("products_cache:" + product_id, product_info的所有字段和值)

// 从队列获取热门商品
function 获取热门商品(start, end):
    // 获取排名靠前的商品ID
    product_ids = Redis.ZREVRANGE("hot_products_queue", start, end)  // 从高到低排序
    
    products = []
    对于每个 product_id in product_ids:
        product_info = Redis.HGETALL("products_cache:" + product_id)
        products.append(product_info)
    
    返回 products

// 设置定时任务
每隔一定时间段(例如1小时):
    执行 定期刷新队列()
```

### 常见的缓存更新策略

[Redis数据库和缓存保持一致性详解](./Redis数据库和缓存如何保持一致性.md)

缓存更新策略有三种

- Cache Aside : 旁路缓存
- Read/Write Through : 读穿 / 写穿策略
- Write Back : 写回策略

> 旁路缓存策略

这个策略是业务中主要使用的更新策略

- 在发生**写操作**的时候 : **先更新数据库, 再删除缓存中的数据**
- 在发生**读操作**的时候 : 先尝试从缓存中获取, 如果没有获取到,  尝试从数据库中获取, 并更新缓存

这个策略中的重点是写操作为什么是**先更新数据库后删除缓存?**

> 如果是先更新缓存再更新数据库呢?

现在我们有两个线程都要访问age : 20这个数据, 其中1号线程要修改这个数据为21. 2号线程要读取这个值

- 对于1号线程 : 执行 1. 删除缓存中的数据 2. 更新库表中的age = 21
- 对于2号线程 : 从缓存中读取的时候, 发现数据不存在, 这个时候会尝试从数据库中获取, 这个时候读取到的是20(old)

这个时候就出现了偏差, 并且因为更新数据库中的数据的时间是相对较长的, 所以相对也更容易触发这个并发问题, 一致性更差, 因为两个操作之间的空隙很大

> 那么现在是先更新数据库再删除缓存呢?

同样我们有两个线程都要访问age : 20这个数据, 其中1号线程要修改这个数据为21. 2号线程要读取这个值

- 对于1号线程 : 执行 1. 更新数据库中的数据 2. 删除缓存
- 对于2号线程 : 缓存命中, 读取到20(old)

也出现了缓存一致性的问题, 那么为什么选用这个方案?

- redis的写操作相对于数据库的写操作, 速度快得多
- 先写数据库再删除缓存这两个操作之间的空隙更小, 更能视作为一个**原子操作**

不过最后也能看出, 这个方案其实更适合**读多写少**的情况

> Write/Read Through : 写/读传透策略

将和数据库的交互交给缓存程序, 用户程序只与缓存打交道, 其实可以看做是旁路缓存的理想情况

- 写操作 : 将数据更新到缓存中, 然后同步更新到数据库中
- 读操作 : 尝试从缓存中读取 ? 返回数据 : 从数据库中读取数据并更新缓存

这个方案在实际开发中并不适用, 因为redis并没有提供管理数据库的功能

> Write Back

和CPU缓存策略中的写回策略是一样的方式, 在缓存中更新数据以后, 将数据打上脏标, 在数据要被移除的时候, 将数据写回到数据库中

适用于 **读少写多** 的情况, 但是这个策略会带来数据不是强一致性的问题, 会有数据丢失的风险. 掉电数据就没了

## Redis实战